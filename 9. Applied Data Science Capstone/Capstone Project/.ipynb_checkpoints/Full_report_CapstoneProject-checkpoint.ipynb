{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Sydney suburbs for opening a new restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUSINESS PROBLEM\n",
    "\n",
    "You are working in a boutique consulting firm specialised in Restaurant Marketing. An client is looking to open a new **Italian restaurant** in Sydney, however, he is not sure about the best location and marketing strategy for his new venue. So you are assigned to help him to develop a comprehensive marketing program. Sydney is a vibrant city that shines all year with spectacular events. It is best known for its tourist attractions and idyllic beaches. Strolling around the city suburbs, it hardly find a clean niche to open up a new restaurants among established competitors without a data-driven methodology. How would you advise your client in deciding his restaurant location using data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA\n",
    "Synthesised from *Start Your Own Restaurant and More: Pizzeria, Cofeehouse, Deli, Bakery, Catering Business* published by [Entrepreneur Press](https://www.entrepreneur.com/article/73384 \"How to Start a Restaurant\"), the following components are deemed as key factors in selecting restaurant location: demographics, traffic density, crime rates, competitor, and property affordability. We may not be able to solve all these factors in such a short period of time, however, some of these considerations could actually be addressed by using available public datasets or web-scraping. \n",
    "\n",
    "1. [**NSW_suburb.geojson**](https://data.gov.au/dataset/ds-dga-91e70237-d9d1-4719-a82f-e71b811154c6/details)\n",
    "This dataset contains all **suburb names** and their **boundry coordinates** in New South Wales, Australia. It will be used for defining suburb boundries and calculating **suburb centres coordinates**. The latter will be used as anchor location for searching venues in *Foursuqare* API.\n",
    "2. [**sydney_suburb_postcode_all.csv**]()\n",
    "I generated this dataset by web-scraping, please see *Methodology* for details.\n",
    "This dataset contains all **suburb names** and **postcodes** within Sydney metro area. It will be used to subset Sydney suburb coordinates from NSW_suburb.geojson.\n",
    "3. [**sydney_property_price.csv**]()\n",
    "I generated this dataset by web-scraping, please see *Methodology* for details\n",
    "This dataset contains median values of sell and rent prices for houses and units in each Sydney suburb. This dataset will be used for plotting property affordability of each suburb.\n",
    "4. [**sydney_demography_by_suburb.csv**]()\n",
    "I generated this dataset by web-scraping, please see *Methodology* for details\n",
    "This dataset comprises **Suburb**, **Population** and **Age**. This dataset will be used for plotting demographics of each suburb.\n",
    "5. [**Sydney_venues.csv**]()\n",
    "List of venues of each suburb. Generated from *Foursquare* API.\n",
    "\n",
    "By using above datasets, we will find suburbs with the least competitors by K-mean clustering with *Foursquare* venues data. Then we will pick up suburbs that have affordable property price, high population density. Last we will look into selected suburb to identify potential locations for opening up a Italian restaurant based on *Foursquare* venues data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHODOLOGY "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import json # library to handle JSON files\n",
    "import folium # library for plot map\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain geojson data\n",
    "\n",
    "Download the **NSW_suburb.geojson** data and open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NSW_suburb.geojson'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-79b7c2916e9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NSW_suburb.geojson'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mNSW_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mNSW_data_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNSW_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNSW_data_feature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NSW_suburb.geojson'"
     ]
    }
   ],
   "source": [
    "with open('NSW_suburb.geojson') as json_data:\n",
    "    NSW_data = json.load(json_data)\n",
    "NSW_data_feature = NSW_data['features']\n",
    "len(NSW_data_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Sydney suburb list\n",
    "\n",
    "I first scraped the list of Sydney suburbs from wiki using `requests` and `Beautifulsoup4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are four pages for the list, so we stored the web links for these four pages into `domain`\n",
    "headers = ({'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "domain = []\n",
    "domain.append(\"https://en.wikipedia.org/wiki/Category:Suburbs_of_Sydney\")\n",
    "domain.append(\"https://en.wikipedia.org/w/index.php?title=Category:Suburbs_of_Sydney&pagefrom=Dharruk%2C+New+South+Wales#mw-pages\")\n",
    "domain.append(\"https://en.wikipedia.org/w/index.php?title=Category:Suburbs_of_Sydney&pagefrom=Macgraths+Hill%0AMcGraths+Hill%2C+New+South+Wales#mw-pages\")\n",
    "domain.append(\"https://en.wikipedia.org/w/index.php?title=Category:Suburbs_of_Sydney&pagefrom=Singletons+Mill%2C+New+South+Wales#mw-pages\")\n",
    "\n",
    "# Create a empty list to store content\n",
    "suburb_list =[]\n",
    "for i in range(len(domain)):\n",
    "    response = get(domain[i], headers=headers)\n",
    "    # Check if get infomation from the target website, \"200\" denotes ok.\n",
    "    print(response)\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # After inspecting the first \"find_all\", the list we need is in [1]. The result will be a list of lists\n",
    "    suburb_list.append(html_soup.find_all('div', class_=\"mw-category\")[1].find_all('div', class_=\"mw-category-group\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After exploring the list, we found the layer for suburb names\n",
    "# instantiate the dataframe\n",
    "Sydney_suburb = pd.DataFrame(columns=[\"Suburb\"])\n",
    "\n",
    "# iterating the list to extract suburb names\n",
    "for i in range(len(suburb_list)):\n",
    "    tmp_list_1 = suburb_list[i]\n",
    "    for j in range(len(tmp_list_1)):\n",
    "        tmp_list_2 = tmp_list_1[j].find_all('a')\n",
    "        for k in range(len(tmp_list_2)):\n",
    "            suburb_name = tmp_list_2[k].contents[0]\n",
    "            Sydney_suburb = Sydney_suburb.append({'Suburb': suburb_name}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first row as it is not a suburb\n",
    "Sydney_suburb = Sydney_suburb[Sydney_suburb['Suburb'] != 'List of Sydney suburbs']\n",
    "\n",
    "# Split the text based on comma into two columns\n",
    "Sydney_suburb = pd.DataFrame(Sydney_suburb.Suburb.str.split(',',1).tolist(),\n",
    "                             columns = ['Suburb','State'])\n",
    "Sydney_suburb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv and open it in excel, change \"sydney central business district\" as \"Sydney\"\n",
    "#Sydney_suburb.to_csv(\"sydney_suburb_wiki.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain Sydney suburb postcode table\n",
    "\n",
    "Secondly, I scraped the postcode table of all Sydney suburbs from [here](https://www.costlessquotes.com.au/postcode_tool/postcode_list_NSW.php).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ({'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "domain = \"https://www.costlessquotes.com.au/postcode_tool/postcode_list_NSW.php\"\n",
    "response = get(domain, headers=headers)\n",
    "# Check if get infomation from the target website, \"200\" denotes ok.\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "postcode_containers = html_soup.find_all('table', class_=\"table\")[0].find_all('tr')\n",
    "\n",
    "# instantiate the dataframe\n",
    "Sydney_area_postcode = pd.DataFrame(columns=[\"Postcode\", \"Areas\"])\n",
    "\n",
    "for i in range(1, len(postcode_containers)):\n",
    "    area_list = postcode_containers[i].find_all('td')[2].find('a').contents[0]\n",
    "    postcode = postcode_containers[i].find_all('td')[0].contents[0]\n",
    "    Sydney_area_postcode = Sydney_area_postcode.append({'Postcode': postcode,\n",
    "                                                        'Areas': area_list},\n",
    "                                                       ignore_index=True)\n",
    "Sydney_area_postcode.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write as a csv file for latter use\n",
    "#Sydney_area_postcode.to_csv('Sydney_area_postcode.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link Sydney suburb with its postcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sydney_area_postcode = pd.read_csv('Sydney_area_postcode.csv')\n",
    "Sydney_suburb = pd.read_csv('sydney_suburb_wiki.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the dataframe\n",
    "Sydney_suburb_postcode = pd.DataFrame(columns=[\"Suburb\", \"Postcode\"])\n",
    "\n",
    "for suburb in Sydney_suburb['Suburb']:\n",
    "    for index in range(len(Sydney_area_postcode['Areas'])):\n",
    "        # This is to seperate items with the same postcode using comma and remove space\n",
    "        area_list = [x.strip(' ') for x in Sydney_area_postcode['Areas'][index].split(',')]\n",
    "        if suburb in area_list:\n",
    "            postcode = Sydney_area_postcode.loc[index, 'Postcode']\n",
    "            Sydney_suburb_postcode = Sydney_suburb_postcode.append({\"Suburb\":suburb, \"Postcode\":postcode}, ignore_index=True)\n",
    "\n",
    "Sydney_suburb_postcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to combine `Sydney_suburb` and `Sydney_suburb_postcode` as `Sydney_suburb_postcode_all`. Since the suburb name format in the geojson file is different from `Sydney_suburb_postcode_all`, we created a column **Suburbs_with_boundries** in `Sydney_suburb_postcode_all` for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge suburb and postcode\n",
    "Sydney_suburb_postcode_all = pd.merge(Sydney_suburb, \n",
    "                               Sydney_suburb_postcode, \n",
    "                               left_on='Suburb', \n",
    "                               right_on='Suburb',\n",
    "                               how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract suburb names from geojson file\n",
    "suburb_list_geojson = []\n",
    "for i in NSW_data_feature:\n",
    "    suburb_list_geojson.append(i['properties']['nsw_loca_2'])\n",
    "\n",
    "# Covert the list to dataframe\n",
    "suburb_list_geojson_df = pd.DataFrame(suburb_list_geojson, columns=['Suburbs_with_boundries'])\n",
    "\n",
    "# Add one more column as key column for merging\n",
    "suburb_list_geojson_df['Suburb_key'] = suburb_list_geojson_df['Suburbs_with_boundries'].str.title()\n",
    "suburb_list_geojson_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sydney_suburb_postcode_all = pd.merge(Sydney_suburb_postcode_all, \n",
    "                               suburb_list_geojson_df, \n",
    "                               left_on='Suburb', \n",
    "                               right_on='Suburb_key',\n",
    "                               how='left')\n",
    "\n",
    "# Remove redundant column\n",
    "Sydney_suburb_postcode_all = Sydney_suburb_postcode_all.drop(['Suburb_key'], axis=1) \n",
    "\n",
    "Sydney_suburb_postcode_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there might be wrong and missing postcodes, I did manual check for the csv file and did changes accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv file and check duplicate and wrong postcode manually according to Domain website\n",
    "#Sydney_suburb_postcode_all.to_csv(\"sydney_suburb_postcode_all.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping demography data based on the Sydney suburb list\n",
    "\n",
    "Once we obtained and curated the Sydney suburb and postcode list, we used it for scraping demography data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test if we can scrap info from a given web\n",
    "\n",
    "=================================================\n",
    "\n",
    "If the return code is 200, then it indicates we successfully scraped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ({'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "domain = \"https://www.domain.com.au/suburb-profile/currawong-beach-nsw-2108\"\n",
    "response = get(domain, headers=headers)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the html file to find the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "house_containers = html_soup.find_all('div', class_=\"suburb-profile__row\")\n",
    "demography = house_containers[0].find_all('div', class_=\"css-jkrtif\")[0].find_all('div', class_=\"css-54bw0x\")\n",
    "demography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start to scrap info for all suburbs\n",
    "\n",
    "Once we are familiar with the html structure, we can do scraping for all suburbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for compiling info into array\n",
    "def getDemography(suburb_names, postcode_list, state='NSW'):\n",
    "    \n",
    "    Demography_list=[]\n",
    "    \n",
    "    for suburb, postcode in zip(suburb_names, postcode_list):\n",
    "        \n",
    "        print(suburb)\n",
    "        \n",
    "        suburb = suburb.replace(' ', '-')\n",
    "            \n",
    "        # create the API request URL\n",
    "        headers = ({'User-Agent':\n",
    "                    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        url = 'https://www.domain.com.au/suburb-profile/{}-nsw-{}'.format(\n",
    "            suburb, \n",
    "            postcode)\n",
    "            \n",
    "        # make the GET request\n",
    "        response = get(url, headers=headers)\n",
    "        \n",
    "        # Parse the html\n",
    "        html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        info_containers = html_soup.find_all('div', class_=\"suburb-profile__row\")\n",
    "        \n",
    "        try:\n",
    "            if info_containers != []:\n",
    "\n",
    "                demography = info_containers[0].find_all('div', class_=\"css-jkrtif\")[0].find_all('div', class_=\"css-54bw0x\")\n",
    "\n",
    "                if demography != []:\n",
    "\n",
    "                    population = demography[0].text\n",
    "                    population = population.replace(',', '')\n",
    "                    age = demography[1].text\n",
    "\n",
    "                else:     \n",
    "                    # sometime there will be a promotion section on the result site, hence demography info locates in different section.\n",
    "                    demography = info_containers[1].find_all('div', class_=\"css-jkrtif\")[0].find_all('div', class_=\"css-54bw0x\")\n",
    "                    \n",
    "                    if demography != []:\n",
    "                        population = demography[0].text\n",
    "                        population = population.replace(',', '')\n",
    "                        age = demography[1].text\n",
    "                    \n",
    "                    else:\n",
    "                        # sometimes there will be no infomation.\n",
    "                        population = \"NA\"\n",
    "                        age = \"NA\"\n",
    "\n",
    "            else:\n",
    "                # sometimes there is no infomation\n",
    "                population = \"NA\"\n",
    "                age = \"NA\" \n",
    "        \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # return only relevant information for suburb\n",
    "        Demography_list.append([(\n",
    "            suburb, \n",
    "            postcode, \n",
    "            population, \n",
    "            age)])\n",
    "        \n",
    "        # Wait a given time bewteen 5 to 15 seconds for scraping the next website to mimic a humanbeing search.\n",
    "        time.sleep(random.randint(5,15))     \n",
    "    \n",
    "    return(Demography_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the whole list into several parts, so we can check abnormality as the html structure may be different for a specific query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_suburb = pd.read_csv('sydney_suburb_postcode_all.csv')\n",
    "sydney_suburb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_demography = getDemography(suburb_names=sydney_suburb['Suburb'].str.lower(), postcode_list=sydney_suburb['Postcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_demography2 = getDemography(suburb_names=sydney_suburb['Suburb'][65:100].str.lower(), postcode_list=sydney_suburb['Postcode'][65:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_demography3 = getDemography(suburb_names=sydney_suburb['Suburb'][100:137].str.lower(), postcode_list=sydney_suburb['Postcode'][100:137])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_demography4 = getDemography(suburb_names=sydney_suburb['Suburb'][137:183].str.lower(), postcode_list=sydney_suburb['Postcode'][137:183])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_demography5 = getDemography(suburb_names=sydney_suburb['Suburb'][183:351].str.lower(), postcode_list=sydney_suburb['Postcode'][183:351])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_demography6 = getDemography(suburb_names=sydney_suburb['Suburb'][351:695].str.lower(), postcode_list=sydney_suburb['Postcode'][351:695])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once finish, concatenate all lists as one\n",
    "sydney_demography_all = sydney_demography + sydney_demography2 + sydney_demography3 + sydney_demography4 + sydney_demography5 + sydney_demography6\n",
    "\n",
    "# Convert the list into a dataframe\n",
    "sydney_demography_list = pd.DataFrame([item for sydney_demography_all in sydney_demography_all for item in sydney_demography_all])\n",
    "sydney_demography_list.columns = ['Suburb',\n",
    "                                 'Postcode',\n",
    "                                 'Population',\n",
    "                                 'Age']\n",
    "sydney_demography_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add \"Suburbs_with_boundries\" as keys for searching boundries later against geojson file. Doing so can make sure no suburb will be missed due to unmatched format\n",
    "# for example there is a dash in \"MOUNT KURING-GAI\" in the geojson file\n",
    "sydney_demography_list['Suburbs_with_boundries'] = sydney_suburb['Suburbs_with_boundries']\n",
    "sydney_demography_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv file and check maunally in excel. \n",
    "#sydney_demography_list.to_csv('sydney_demography_by_suburb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_demography_data = pd.read_csv('sydney_demography_by_suburb.csv')\n",
    "sydney_demography_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset the NSW geojson file to only contain Sydney suburbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSW_data_feature_new = []\n",
    "Suburb_list = []\n",
    "\n",
    "for i in range(len(NSW_data_feature)):\n",
    "    # check if the suburb in Sydney\n",
    "    if NSW_data['features'][i]['properties']['nsw_loca_2'] in sydney_demography_data['Suburbs_with_boundries'].tolist():\n",
    "        \n",
    "        # This part is to deal with suburb with the same name and not in Sydney area\n",
    "        postcode = NSW_data['features'][i]['properties']['nsw_loca_4']\n",
    "        suburb = NSW_data['features'][i]['properties']['nsw_loca_2']\n",
    "        \n",
    "        if postcode is not None:\n",
    "            postcode_sydney = sydney_demography_data.loc[sydney_demography_data['Suburbs_with_boundries'] == suburb, 'Postcode'].tolist()[0]\n",
    "                     \n",
    "            # \"postcode_sydney\" is int, you need to convert to str to be able to compare with j, which is a str\n",
    "            if postcode == str(postcode_sydney):\n",
    "                NSW_data_feature_new.append(NSW_data_feature[i])\n",
    "                Suburb_list.append(NSW_data['features'][i]['properties']['nsw_loca_2'].title())\n",
    "        else:\n",
    "            NSW_data_feature_new.append(NSW_data_feature[i])\n",
    "            Suburb_list.append(NSW_data['features'][i]['properties']['nsw_loca_2'].title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of final list, we found that the total number is still not 698 as in the sydney_demography_data. There must be some repeat in NSW_data_feature_new\n",
    "len(NSW_data_feature_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find repeated items in a list\n",
    "def Repeat(x): \n",
    "    _size = len(x) \n",
    "    repeated = [] \n",
    "    for i in range(_size): \n",
    "        k = i + 1\n",
    "        for j in range(k, _size): \n",
    "            if x[i] == x[j] and x[i] not in repeated: \n",
    "                repeated.append(x[i]) \n",
    "    return repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the repeat suburb names, there are two of them ['Chatswood West', 'Lovett Bay']\n",
    "print(Repeat(Suburb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if they have postcode\n",
    "postcode_test = []\n",
    "for i in range(len(NSW_data_feature)):\n",
    "    if NSW_data['features'][i]['properties']['nsw_loca_2'] == 'Chatswood West'.upper():\n",
    "        postcode_test.append(NSW_data['features'][i]['properties']['nsw_loca_4'])\n",
    "\n",
    "# No wonder they were selected into the final list, because they do not have postcodes for us to select and end up put into the final list.\n",
    "postcode_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check if this is just duplicates in NSW_suburb.geojson file\n",
    "loc_pid_test = []\n",
    "for i in range(len(NSW_data_feature)):\n",
    "    if NSW_data['features'][i]['properties']['nsw_loca_2'] == 'Lovett Bay'.upper():\n",
    "        loc_pid_test.append(NSW_data['features'][i]['properties']['loc_pid'])\n",
    "        \n",
    "# Looks like they are the same suburb ['NSW5092', 'NSW5092']\n",
    "loc_pid_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just keep one of them in the final list\n",
    "NSW_data_feature_final = []\n",
    "tmp_list = []\n",
    "\n",
    "for i in range(len(NSW_data_feature_new)):\n",
    "    # check if the suburb name is one of ['Chatswood West', 'Lovett Bay']\n",
    "    if NSW_data_feature_new[i]['properties']['nsw_loca_2'].title() in Repeat(Suburb_list):\n",
    "        \n",
    "        tmp_list.append(NSW_data_feature_new[i])\n",
    "        \n",
    "    else:\n",
    "        NSW_data_feature_final.append(NSW_data_feature_new[i])\n",
    "\n",
    "NSW_data_feature_final.append(tmp_list[1])\n",
    "NSW_data_feature_final.append(tmp_list[3])\n",
    "\n",
    "len(NSW_data_feature_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the final list to the 'features' layer of NSW geojson list. So the geojson file only contains suburbs in Sydney\n",
    "NSW_data['features'] = NSW_data_feature_final\n",
    "\n",
    "# Save this new geojson file\n",
    "#from json import dump\n",
    "#with open('Sydney_suburb.geojson', 'w') as f:\n",
    "#   dump(NSW_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping property median price data based on the Sydney suburb list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_suburb = pd.read_csv('sydney_demography_by_suburb.csv')\n",
    "sydney_suburb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for compiling info into array\n",
    "def getMedianPrice(suburb_names, postcode_list, state='NSW'):\n",
    "    \n",
    "    # For display progress bar\n",
    "    bar = progressbar.ProgressBar(maxval=sydney_suburb.shape[0],\n",
    "                                  widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    \n",
    "    price_list=[]\n",
    "    \n",
    "    bar.start()\n",
    "    \n",
    "    for suburb, postcode in zip(suburb_names, postcode_list):\n",
    "        \n",
    "        bar.update(sydney_suburb['Suburb'].tolist().index(suburb)+1)\n",
    "                    \n",
    "        # create the API request URL\n",
    "        headers = ({'User-Agent':\n",
    "                    'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'})\n",
    "        url = 'https://www.realestate.com.au/neighbourhoods/{}-{}-nsw'.format(\n",
    "            suburb, \n",
    "            postcode)\n",
    "            \n",
    "        # make the GET request\n",
    "        response = get(url, headers=headers)\n",
    "        \n",
    "        html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        house_containers = html_soup.find_all('div', class_=\"section\", id =\"median-price\")\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if house_containers != []:    \n",
    "\n",
    "                median_price = house_containers[0].find_all('div', class_=\"price h1 strong\")\n",
    "\n",
    "                median_price_house_buy = median_price[0].text\n",
    "                median_price_house_buy = median_price_house_buy.replace('$', '')\n",
    "                median_price_house_buy = median_price_house_buy.replace(',', '')\n",
    "\n",
    "                median_price_house_rent = median_price[1].text\n",
    "                median_price_house_rent = median_price_house_rent.replace('$', '')\n",
    "                median_price_house_rent = median_price_house_rent.replace(',', '')\n",
    "                median_price_house_rent = median_price_house_rent.replace(' PW', '')\n",
    "\n",
    "                median_price_unit_buy = median_price[2].text\n",
    "                median_price_unit_buy = median_price_unit_buy.replace('$', '')\n",
    "                median_price_unit_buy = median_price_unit_buy.replace(',', '')\n",
    "\n",
    "                median_price_unit_rent = median_price[3].text\n",
    "                median_price_unit_rent = median_price_unit_rent.replace('$', '')\n",
    "                median_price_unit_rent = median_price_unit_rent.replace(',', '')\n",
    "                median_price_unit_rent = median_price_unit_rent.replace(' PW', '')\n",
    "\n",
    "            else:\n",
    "                median_price_house_buy = \"no data\"\n",
    "                median_price_house_rent = \"no data\"\n",
    "                median_price_unit_buy = \"no data\"\n",
    "                median_price_unit_rent = \"no data\"\n",
    "       \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        # return only relevant information for suburb\n",
    "        price_list.append([(\n",
    "            suburb, \n",
    "            postcode, \n",
    "            median_price_house_buy, \n",
    "            median_price_house_rent, \n",
    "            median_price_unit_buy, \n",
    "            median_price_unit_rent)])\n",
    "        \n",
    "        # Wait a given time bewteen 1 to 15 seconds for scraping the next website to mimic a humanbeing search.\n",
    "        time.sleep(random.randint(5,10))     \n",
    "    \n",
    "    return(price_list)\n",
    "\n",
    "    bar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_property = getMedianPrice(suburb_names=sydney_suburb['Suburb'], postcode_list=sydney_suburb['Postcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_property_price = pd.DataFrame([item for sydney_property in sydney_property for item in sydney_property])\n",
    "sydney_property_price.columns = ['Suburb',\n",
    "                                 'Postcode',\n",
    "                                 'House_buy',\n",
    "                                 'House_rent',\n",
    "                                 'Unit_buy',\n",
    "                                 'Unit_rent']\n",
    "sydney_property_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge demograph and property tables as one dataset\n",
    "\n",
    "sydney_demograph_property_by_suburb = pd.merge(sydney_suburb,\n",
    "                                               sydney_property_price,\n",
    "                                               left_on = \"Suburb\",\n",
    "                                               right_on = \"Suburb\",\n",
    "                                               how = \"left\"\n",
    "                                              )\n",
    "sydney_demograph_property_by_suburb.drop(['Postcode_y'], inplace=True, axis=1)\n",
    "sydney_demograph_property_by_suburb.rename(columns={'Postcode_x':'Postcode', 'Suburbs_with_boundries':'Suburb_name_geojson'}, inplace=True)\n",
    "sydney_demograph_property_by_suburb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repalce str 'no data' as np.NaN, so that we can then assign data type as float\n",
    "sydney_demograph_property_by_suburb['House_buy'] = sydney_demograph_property_by_suburb['House_buy'].replace(['no data'], np.NaN)\n",
    "sydney_demograph_property_by_suburb['House_rent'] = sydney_demograph_property_by_suburb['House_rent'].replace(['no data'], np.NaN)\n",
    "sydney_demograph_property_by_suburb['Unit_buy'] = sydney_demograph_property_by_suburb['Unit_buy'].replace(['no data'], np.NaN)\n",
    "sydney_demograph_property_by_suburb['Unit_rent'] = sydney_demograph_property_by_suburb['Unit_rent'].replace(['no data'], np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct data type in each column\n",
    "sydney_demograph_property_by_suburb['House_buy'] = sydney_demograph_property_by_suburb['House_buy'].astype(float)\n",
    "sydney_demograph_property_by_suburb['House_rent'] = sydney_demograph_property_by_suburb['House_rent'].astype(float)\n",
    "sydney_demograph_property_by_suburb['Unit_buy'] = sydney_demograph_property_by_suburb['Unit_buy'].astype(float)\n",
    "sydney_demograph_property_by_suburb['Unit_rent'] = sydney_demograph_property_by_suburb['Unit_rent'].astype(float)\n",
    "sydney_demograph_property_by_suburb['Postcode'] = sydney_demograph_property_by_suburb['Postcode'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modeling\n",
    "Using sklearn package to model data.\n",
    "\n",
    "As **House_rent** and **House_buy** have linear relationship, we can use this to predict missing values for both **House_buy** and **House_rent**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
    "for key, value in {'Unit_rent':'House_rent', 'House_buy':'Unit_buy', 'Unit_buy':'Unit_rent', 'House_rent':'House_buy'}.items():\n",
    "    \n",
    "    # Store the image index in i \n",
    "    i = list({'Unit_rent':'House_rent', 'House_buy':'Unit_buy', 'Unit_buy':'Unit_rent', 'House_rent':'House_buy'}.keys()).index(key) +1\n",
    "    \n",
    "    # plot figures in 2 by 2 matrix and start from 1 to 4\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.regplot(y=value, x=key,\n",
    "            data=sydney_demograph_property_by_suburb[sydney_demograph_property_by_suburb[[value, key]].notnull().all(1)],\n",
    "               color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows that need to be predicted, which only have one value for either **House_rent** or **House_buy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store rows that have both 'house_rent' and 'house_buy' as NaN\n",
    "data_all_NaN = sydney_demograph_property_by_suburb[sydney_demograph_property_by_suburb[['House_rent', 'House_buy']].isnull().all(1)]\n",
    "\n",
    "# Select rows with at least one NaN for column 'House_rent' and 'House_buy'\n",
    "data_for_pred = sydney_demograph_property_by_suburb[sydney_demograph_property_by_suburb[['House_rent', 'House_buy']].isnull().any(1)]\n",
    "\n",
    "# Select rows with at least one non-NaN for column 'House_rent' and 'House_buy'\n",
    "data_for_pred = One_price_data[One_price_data[['House_rent', 'House_buy']].notnull().any(1)]\n",
    "\n",
    "# Fill NaN as 0 so can be used in the following for loop\n",
    "data_for_pred = data_for_pred[['Suburb', 'Postcode', 'House_rent', 'House_buy']].fillna(0)\n",
    "\n",
    "data_for_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select rows that will be used for modeling, which have values for **House_rent** and **House_buy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_model = sydney_demograph_property_by_suburb[sydney_demograph_property_by_suburb[['House_rent', 'House_buy']].notnull().all(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating train and test dataset\n",
    "\n",
    "Train/Test Split involves splitting the dataset into training and testing sets respectively, which are mutually exclusive. After which, you train with the training set and test with the testing set. \n",
    "This will provide a more accurate evaluation on out-of-sample accuracy because the testing dataset is not part of the dataset that have been used to train the data. It is more realistic for real world problems.\n",
    "\n",
    "This means that we know the outcome of each data point in this dataset, making it great to test with! And since this data has not been used to train the model, the model has no knowledge of the outcome of these data points. So, in essence, it is truly an out-of-sample testing.\n",
    "\n",
    "Lets split our dataset into train and test sets, 80% of the entire data for training, and the 20% for testing. We create a mask to select random rows using __np.random.rand()__ function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(data_for_model)) < 0.8\n",
    "train = data_for_model[msk]\n",
    "test = data_for_model[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simple Regression Model\n",
    "Linear Regression fits a linear model with coefficients $\\theta = (\\theta_1, ..., \\theta_n)$ to minimize the 'residual sum of squares' between the independent x in the dataset, and the dependent y by the linear approximation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "regr = linear_model.LinearRegression()\n",
    "train_x = np.asanyarray(train[['House_buy']])\n",
    "train_y = np.asanyarray(train[['House_rent']])\n",
    "regr.fit (train_x, train_y)\n",
    "# The coefficients\n",
    "print ('Coefficients: ', regr.coef_)\n",
    "print ('Intercept: ',regr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train.House_buy, train.House_rent,  color='blue')\n",
    "plt.plot(train_x, regr.coef_[0][0]*train_x + regr.intercept_[0], '-r')\n",
    "plt.xlabel(\"House buy median price\")\n",
    "plt.ylabel(\"House rent median price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation\n",
    "we compare the actual values and predicted values to calculate the accuracy of a regression model. Evaluation metrics provide a key role in the development of a model, as it provides insight to areas that require improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "test_x = np.asanyarray(test[['House_buy']])\n",
    "test_y = np.asanyarray(test[['House_rent']])\n",
    "test_y_hat = regr.predict(test_x)\n",
    "\n",
    "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_hat - test_y)))\n",
    "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_hat - test_y) ** 2))\n",
    "print(\"R2-score: %.2f\" % r2_score(test_y_hat , test_y) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prediction\n",
    "\n",
    "We now can use the model to predict missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "for x, y, i, k in zip(data_for_pred.House_buy, data_for_pred.House_rent, data_for_pred.Suburb, data_for_pred.Postcode):\n",
    "    if y != 0:\n",
    "        x_pred = (y - regr.intercept_[0])/regr.coef_[0][0]\n",
    "        new_data.append([(i, k, y, x_pred)])\n",
    "    else:\n",
    "        y_pred = regr.coef_[0][0]*x + regr.intercept_[0]\n",
    "        new_data.append([(i, k, y_pred, x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list into a dataframe\n",
    "data_after_pred = pd.DataFrame([item for new_data in new_data for item in new_data])\n",
    "data_after_pred.columns = ['Suburb',\n",
    "                           'Postcode',\n",
    "                           'House_rent',\n",
    "                           'House_buy']\n",
    "data_after_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all three dataframes together.\n",
    "data_all = pd.concat([data_for_model[['Suburb', 'Postcode', 'House_rent', 'House_buy']], data_after_pred, data_all_NaN[['Suburb', 'Postcode', 'House_rent', 'House_buy']]], \n",
    "                     ignore_index=True)\n",
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.merge(sydney_demograph_property_by_suburb, \n",
    "                      data_all, \n",
    "                      left_on='Suburb',\n",
    "                     right_on='Suburb',\n",
    "                     how='left')\n",
    "\n",
    "# remove redundant columns and rename columns\n",
    "data_final_tmp = data_final.drop(['Postcode_y', 'House_buy_x', 'House_rent_x'], axis=1)\n",
    "data_final_tmp = data_final_tmp.rename(columns = {'Postcode_x': 'Postcode', 'House_rent_y': 'House_rent', 'House_buy_y':'House_buy'}, inplace=False)\n",
    "\n",
    "# Scale buy value by 10000\n",
    "data_final_tmp['Unit_buy'] = data_final_tmp['Unit_buy']/1000000\n",
    "data_final_tmp['House_buy'] = data_final_tmp['House_buy']/1000000\n",
    "\n",
    "# Rename the buy column to indicate the scale is million\n",
    "data_final_tmp = data_final_tmp.rename(columns = {'Unit_buy': 'Unit_buy/M', 'House_buy':'House_buy/M'}, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this dataframe as the final table for suburb, postcode, demography and property price\n",
    "#data_final_tmp.to_csv('sydney_postcode_demo_property_final.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choropleth map \n",
    "Now, let's create our own `Choropleth` map of population, age and property median price for Sydney."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Population map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sydney latitude and longitude values\n",
    "latitude = -33.892319\n",
    "longitude = 151.146167\n",
    "\n",
    "# create a plain Sydney map\n",
    "population_map = folium.Map(location=[latitude, longitude], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "# create a list for population scale\n",
    "bins = list(range(0, 60000, 10000))\n",
    "\n",
    "# generate choropleth map using the total population of each suburb in Sydney\n",
    "population_map.choropleth(\n",
    "    geo_data=NSW_data,\n",
    "    data=sydney_demography_data,\n",
    "    columns=['Suburbs_with_boundries', 'Population'],\n",
    "    key_on='feature.properties.nsw_loca_2',\n",
    "    fill_color='BuGn', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.9,\n",
    "    legend_name='Population by Suburb',\n",
    "    bins=bins,\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "# The map sometimes is too big to open in Jupyter, so export the map and open it in another Tab.\n",
    "population_map.save(os.path.join('/Users/jun/Dropbox/Course/coursera/IBM_Data_Science/Course9_Applied Data Science Capstone/github_project', 'GeoJSON_and_choropleth_demography.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Age map\n",
    "\n",
    "We need to do some modifications for **Age** as it is category string and also contains missing value. We need to replace missing value as 60+ and create a new column with number to indicate the age range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If suburb has no value for age, I then assume that this suburb age range should be 60+\n",
    "sydney_demography_data[['Age']] = sydney_demography_data[['Age']].fillna('60+')\n",
    "\n",
    "# Now we have 4 categories for the age range\n",
    "sydney_demography_data.Age.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to indicate the age range\n",
    "sydney_demography_data['Age_map'] = sydney_demography_data['Age'].map({'5 to 19': 6, '20 to 39': 21, '40 to 59': 41, '60+':61}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sydney latitude and longitude values\n",
    "latitude = -33.892319\n",
    "longitude = 151.146167\n",
    "\n",
    "# create a plain Sydney map\n",
    "population_map = folium.Map(location=[latitude, longitude], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "# Create a bin to plot age range\n",
    "bins = [5, 20, 40, 60, 100]\n",
    "\n",
    "# generate choropleth map using the total population of each suburb in Sydney\n",
    "population_map.choropleth(\n",
    "    geo_data=NSW_data,\n",
    "    data=sydney_demography_data,\n",
    "    columns=['Suburbs_with_boundries', 'Age_map'],\n",
    "    key_on='feature.properties.nsw_loca_2',\n",
    "    fill_color='YlOrRd', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.9,\n",
    "    legend_name='Age by Suburb',\n",
    "    bins=bins,\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "# The map sometimes is too big to open in Jupyter, so export the map and open it in another Tab.\n",
    "population_map.save(os.path.join('/Users/jun/Dropbox/Course/coursera/IBM_Data_Science/Course9_Applied Data Science Capstone/github_project', 'GeoJSON_and_choropleth_age.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Median price map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sydney latitude and longitude values\n",
    "latitude = -33.892319\n",
    "longitude = 151.146167\n",
    "\n",
    "# create a plain Sydney map\n",
    "population_map = folium.Map(location=[latitude, longitude], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "# create a numpy array of length 6 and has linear spacing from the minium total immigration to the maximum total immigration\n",
    "threshold_scale = np.linspace(data_final_tmp['House_buy/M'].min(),\n",
    "                              data_final_tmp['House_buy/M'].max(),\n",
    "                              10, dtype=int)\n",
    "threshold_scale = threshold_scale.tolist() # change the numpy array to a list\n",
    "threshold_scale[-1] = threshold_scale[-1] + 1 # make sure that the last value of the list is greater than the maximum immigration\n",
    "\n",
    "\n",
    "# generate choropleth map using the total population of each suburb in Sydney\n",
    "population_map.choropleth(\n",
    "    geo_data=Sydney_data,\n",
    "    data=data_final_tmp,\n",
    "    columns=['Suburb_name_geojson', 'House_buy/M'],\n",
    "    key_on='feature.properties.nsw_loca_2',\n",
    "    fillColor='#gray',\n",
    "    threshold_scale=threshold_scale,\n",
    "    fill_color='BuPu', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.9,\n",
    "    legend_name='House median price by Suburb (million)',\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "# The map sometimes is too big to open in Jupyter, so export the map and open it in another Tab.\n",
    "population_map.save(os.path.join('/Users/jun/Dropbox/Course/coursera/IBM_Data_Science/Course9_Applied Data Science Capstone/github_project', 'GeoJSON_and_choropleth_median_price.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring Sydney suburbs with Foursuqre API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "# import k-means from clustering stage\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import requests # library to handle requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sydney_suburb.geojson') as json_data:\n",
    "    Sydney_data = json.load(json_data)\n",
    "\n",
    "# Store features layer\n",
    "suburb_data = Sydney_data['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the question, We assume the centre coordinates of the polygon as the suburb centre. We then define a function for centre coordinates calculation using boundry coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the centroid of a list of (x, y) tuples\n",
    "def centeroidnp(arr):\n",
    "    length = arr.shape[0]\n",
    "    sum_x = np.sum(arr[:, 0])\n",
    "    sum_y = np.sum(arr[:, 1])\n",
    "    return sum_x/length, sum_y/length\n",
    "\n",
    "# define the dataframe columns\n",
    "column_names = ['Suburb', 'Latitude','Longitude'] \n",
    "\n",
    "# instantiate the dataframe\n",
    "Sydney_suburbs = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for data in suburb_data:  \n",
    "    suburb_name = data['properties']['nsw_loca_2']    \n",
    "    suburb_latlon = centeroidnp(np.asarray(data['geometry']['coordinates'][0][0]))    \n",
    "    suburb_lat = suburb_latlon[1]\n",
    "    suburb_lon = suburb_latlon[0]  \n",
    "    Sydney_suburbs = Sydney_suburbs.append({'Suburb': suburb_name,\n",
    "                                            'Latitude': suburb_lat,\n",
    "                                            'Longitude': suburb_lon}, ignore_index=True)\n",
    "    \n",
    "Sydney_suburbs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sydney metro area has {} suburbs'.format(Sydney_suburbs.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to start utilizing the Foursquare API to explore the suburbs and segment them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Foursquare Credentials and Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'UFUOK1DDHYEBMIKZCVZE1VWLZ5S4MNUMRBYKO0UTWZ5MV42Y' # your Foursquare ID\n",
    "CLIENT_SECRET = 'PNLQYCQGW2QIHAYNRU42Q4HCDMK4SOYG3YVTKEQIR1TD3XVS' # your Foursquare Secret\n",
    "VERSION = '20191005' # Foursquare API version\n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to repeat the same process to all the suburbs in Sydney."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNearbyVenues(names, latitudes, longitudes, radius=500, LIMIT = 100):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Suburb', \n",
    "                  'Suburb Latitude', \n",
    "                  'Suburb Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    # Wait a given time bewteen 3 to 8 seconds for scraping the next website to mimic a humanbeing search.\n",
    "        #time.sleep(random.randint(3,8))\n",
    "    \n",
    "    return(nearby_venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sydney_venues = getNearbyVenues(names=Sydney_suburbs['Suburb'],\n",
    "                                   latitudes=Sydney_suburbs['Latitude'],\n",
    "                                   longitudes=Sydney_suburbs['Longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the size of the resulting dataframe\n",
    "print(sydney_venues.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how many venues were returned for each suburbs and list the top 20\n",
    "sydney_venues_num = sydney_venues.groupby('Suburb').count()\n",
    "sydney_venues_num = sydney_venues_num.drop(columns=['Suburb Latitude', 'Suburb Longitude', 'Venue Latitude', 'Venue Longitude', 'Venue Category'])\n",
    "sydney_venues_num = sydney_venues_num.sort_values(['Venue'], ascending=False).reset_index(drop=False)\n",
    "sydney_venues_num['Suburb'] = sydney_venues_num['Suburb'].str.title()\n",
    "print(sydney_venues_num.shape[0])\n",
    "sydney_venues_num.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, only 565 suburbs returned venues. This may because the arbitary choice of suburb centre is not the real suburb centre, we should find a better way to define suburb centre in the future. \n",
    "\n",
    "We can aslo see the top 20 suburbs with the most venues number from the `sydney_venues_num` table. Note that we only limited 100 when retrieving data from Foursquare, but this does not impact the rank.\n",
    "\n",
    "Let's then find out how many unique categories can be curated from all the returned venues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} uniques categories.'.format(len(sydney_venues['Venue Category'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using one hot encoding to create a matrix table for each suburb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "sydney_onehot = pd.get_dummies(sydney_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add suburb column back to dataframe\n",
    "sydney_onehot['Suburb'] = sydney_venues['Suburb'] \n",
    "\n",
    "# move suburb column to the first column\n",
    "fixed_columns = [sydney_onehot.columns[-1]] + list(sydney_onehot.columns[:-1])\n",
    "sydney_onehot = sydney_onehot[fixed_columns]\n",
    "\n",
    "sydney_onehot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_grouped = sydney_onehot.groupby('Suburb').mean().reset_index()\n",
    "sydney_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find each suburb along with the top 10 most common venues and save into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's write a function to sort the venues in descending order.\n",
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Suburb']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "suburbs_venues_sorted = pd.DataFrame(columns=columns)\n",
    "suburbs_venues_sorted['Suburb'] = sydney_grouped['Suburb']\n",
    "\n",
    "for ind in np.arange(sydney_grouped.shape[0]):\n",
    "    suburbs_venues_sorted.iloc[ind, 1:] = return_most_common_venues(sydney_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "suburbs_venues_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run *k*-means to cluster the suburbs into clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 4\n",
    "\n",
    "sydney_grouped_clustering = sydney_grouped.drop('Suburb', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(sydney_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add clustering labels\n",
    "suburbs_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n",
    "\n",
    "sydney_merged = Sydney_suburbs\n",
    "\n",
    "# merge sydney_grouped with sydney_data to add latitude/longitude for each neighborhood\n",
    "sydney_merged = sydney_merged.join(suburbs_venues_sorted.set_index('Suburb'), on='Suburb')\n",
    "\n",
    "sydney_merged.head() # check the last columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN in cluster labels as -1\n",
    "sydney_merged['Cluster Labels'] = sydney_merged['Cluster Labels'].fillna(-1)\n",
    "sydney_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dtype as int for column 'Cluster Labels'\n",
    "sydney_merged['Cluster Labels'] = sydney_merged['Cluster Labels'].astype(int)\n",
    "sydney_merged.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's visualize the resulting clusters along with population, age and property price.\n",
    "\n",
    "Cluster with population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sydney latitude and longitude values\n",
    "latitude = -33.892319\n",
    "longitude = 151.146167\n",
    "\n",
    "# create a plain Sydney map\n",
    "population_map = folium.Map(location=[latitude, longitude], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "# create a list for population scale\n",
    "bins = list(range(0, 60000, 10000))\n",
    "\n",
    "# generate choropleth map using the total population of each suburb in Sydney\n",
    "population_map.choropleth(\n",
    "    geo_data=NSW_data,\n",
    "    data=sydney_demography_data,\n",
    "    columns=['Suburbs_with_boundries', 'Population'],\n",
    "    key_on='feature.properties.nsw_loca_2',\n",
    "    fill_color='BuGn', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.9,\n",
    "    legend_name='Population by Suburb',\n",
    "    bins=bins,\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(sydney_merged['Latitude'], sydney_merged['Longitude'], sydney_merged['Suburb'], sydney_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=1).add_to(population_map)\n",
    "    \n",
    "import os\n",
    "# The map sometimes is too big to open in Jupyter, so export the map and open it in another Tab.\n",
    "population_map.save(os.path.join('/Users/jun/Dropbox/Course/coursera/IBM_Data_Science/Course9_Applied Data Science Capstone/github_project', 'GeoJSON_and_choropleth_cluster_population.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with Age range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sydney latitude and longitude values\n",
    "latitude = -33.892319\n",
    "longitude = 151.146167\n",
    "\n",
    "# create a plain Sydney map\n",
    "population_map = folium.Map(location=[latitude, longitude], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "# Create a bin to plot age range\n",
    "bins = [5, 20, 40, 60, 100]\n",
    "\n",
    "# generate choropleth map using the total population of each suburb in Sydney\n",
    "population_map.choropleth(\n",
    "    geo_data=NSW_data,\n",
    "    data=sydney_demography_data,\n",
    "    columns=['Suburbs_with_boundries', 'Age_map'],\n",
    "    key_on='feature.properties.nsw_loca_2',\n",
    "    fill_color='YlOrRd', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.9,\n",
    "    legend_name='Age by Suburb',\n",
    "    bins=bins,\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(sydney_merged['Latitude'], sydney_merged['Longitude'], sydney_merged['Suburb'], sydney_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=1).add_to(population_map)\n",
    "\n",
    "import os\n",
    "# The map sometimes is too big to open in Jupyter, so export the map and open it in another Tab.\n",
    "population_map.save(os.path.join('/Users/jun/Dropbox/Course/coursera/IBM_Data_Science/Course9_Applied Data Science Capstone/github_project', 'GeoJSON_and_choropleth_cluster_age.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster with property price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sydney latitude and longitude values\n",
    "latitude = -33.892319\n",
    "longitude = 151.146167\n",
    "\n",
    "# create a plain Sydney map\n",
    "population_map = folium.Map(location=[latitude, longitude], zoom_start=11, tiles='cartodbpositron')\n",
    "\n",
    "# import data for median price\n",
    "data_final_tmp = pd.read_csv('sydney_postcode_demo_property_final.csv')\n",
    "\n",
    "# create a numpy array of length 6 and has linear spacing from the minium total immigration to the maximum total immigration\n",
    "threshold_scale = np.linspace(data_final_tmp['House_buy/M'].min(),\n",
    "                              data_final_tmp['House_buy/M'].max(),\n",
    "                              10, dtype=int)\n",
    "threshold_scale = threshold_scale.tolist() # change the numpy array to a list\n",
    "threshold_scale[-1] = threshold_scale[-1] + 1 # make sure that the last value of the list is greater than the maximum immigration\n",
    "\n",
    "# generate choropleth map using the total population of each suburb in Sydney\n",
    "population_map.choropleth(\n",
    "    geo_data=Sydney_data,\n",
    "    data=data_final_tmp,\n",
    "    columns=['Suburb_name_geojson', 'House_buy/M'],\n",
    "    key_on='feature.properties.nsw_loca_2',\n",
    "    fillColor='#gray',\n",
    "    threshold_scale=threshold_scale,\n",
    "    fill_color='BuPu', \n",
    "    fill_opacity=0.7, \n",
    "    line_opacity=0.9,\n",
    "    legend_name='House median price by Suburb (million)',\n",
    "    reset=True\n",
    ")\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(kclusters)\n",
    "ys = [i + x + (i*x)**2 for i in range(kclusters)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lon, poi, cluster in zip(sydney_merged['Latitude'], sydney_merged['Longitude'], sydney_merged['Suburb'], sydney_merged['Cluster Labels']):\n",
    "    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lon],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=1).add_to(population_map)\n",
    "\n",
    "import os\n",
    "# The map sometimes is too big to open in Jupyter, so export the map and open it in another Tab.\n",
    "population_map.save(os.path.join('/Users/jun/Dropbox/Course/coursera/IBM_Data_Science/Course9_Applied Data Science Capstone/github_project', 'GeoJSON_and_choropleth_cluster_median_price.html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can examine each cluster and determine the discriminating venue categories that distinguish each cluster. Based on the defining categories, we can then assign a name to each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sydney_merged.loc[sydney_merged['Cluster Labels'] == 0, sydney_merged.columns[[0] + list(range(4, sydney_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sydney_merged.loc[sydney_merged['Cluster Labels'] == 1, sydney_merged.columns[[0] + list(range(4, sydney_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_merged.loc[sydney_merged['Cluster Labels'] == 2, sydney_merged.columns[[0] + list(range(4, sydney_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sydney_merged.loc[sydney_merged['Cluster Labels'] == 3, sydney_merged.columns[[0] + list(range(4, sydney_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sydney_merged.loc[sydney_merged['Cluster Labels'] == -1, sydney_merged.columns[[0] + list(range(4, sydney_merged.shape[1]))]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that cluster 2 is differentiated from other clusters with restaurants. We then can narrow down the candidatial suburb list from cluster 2.\n",
    "\n",
    "let's first insert the cluster labeling into dataframe with demography and median price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sydney_demography_data_cluster = pd.merge(data_final_tmp,\n",
    "                                         sydney_merged[['Suburb', 'Cluster Labels']],\n",
    "                                         left_on = 'Suburb_name_geojson',\n",
    "                                         right_on = 'Suburb',\n",
    "                                         how = 'left')\n",
    "# remove redundant column and rename column\n",
    "sydney_demography_data_cluster = sydney_demography_data_cluster.drop(columns=['Suburb_y'])\n",
    "sydney_demography_data_cluster = sydney_demography_data_cluster.rename(columns={'Suburb_x':'Suburb'})\n",
    "# set 'Age' as category type and reorder the category\n",
    "sydney_demography_data_cluster['Age'] = sydney_demography_data_cluster['Age'].astype('category')\n",
    "sydney_demography_data_cluster['Age'].cat.reorder_categories(['5 to 19', '20 to 39', '40 to 59', '60+'], inplace=True)\n",
    "\n",
    "sydney_demography_data_cluster.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's further narrow down the list by make a 2D scatter plot (Population vs. Houser_buy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "ax = sns.scatterplot(x=\"Population\", y=\"House_buy/M\", hue='Age', s=80,\n",
    "                     data=sydney_demography_data_cluster[sydney_demography_data_cluster['Cluster Labels'] == 2])\n",
    "plt.savefig(\"population_price_age_cluster2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking the scatterplot, we can identify there are 5 suburbs fall into the category that with relatively low property price, high population density and middle age. Let's list them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suburb_candidate = sydney_demography_data_cluster[((sydney_demography_data_cluster['Cluster Labels'] == 2) & (sydney_demography_data_cluster['Population'] > 23000) & (sydney_demography_data_cluster['House_buy/M']<2.5))]\n",
    "suburb_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look of the composition of restaurant in these 5 suburbs.\n",
    "sydney_grouped_sum = sydney_onehot.groupby('Suburb').sum().reset_index()\n",
    "suburb_candidate_restaurant = sydney_grouped_sum.loc[sydney_grouped_sum['Suburb'].isin(list(suburb_candidate['Suburb'].str.upper()))]\n",
    "\n",
    "\n",
    "# Only select Restaurant columns\n",
    "suburb_candidate_restaurant = suburb_candidate_restaurant.loc[:, suburb_candidate_restaurant.columns.str.contains('Restaurant')]\n",
    "\n",
    "suburb_candidate_restaurant['Suburb'] = sydney_grouped_sum['Suburb']\n",
    "\n",
    "# move suburb column to the first column\n",
    "fixed_columns = [suburb_candidate_restaurant.columns[-1]] + list(suburb_candidate_restaurant.columns[:-1])\n",
    "suburb_candidate_restaurant = suburb_candidate_restaurant[fixed_columns]\n",
    "\n",
    "suburb_candidate_restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then Let's find the top 10 most common restaurant types in respective suburb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in list(suburb_candidate_restaurant.index):\n",
    "    print(\"----\"+suburb_candidate_restaurant.loc[index, :][0]+\"----\")\n",
    "    print(suburb_candidate_restaurant.loc[index, :][1:].sort_values(ascending=False).head(10))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Italian restauant is not common in these 5 suburbs. The most common venue in Ryde is Caf, that's why we see no restaurants list for Ryde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS AND DISCUSSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through out this data analysis pipeline, we started from understanding the problem to acheiving final results by using web-scraping, Folium map, Foursquare API and K-mean clustering. We identified 5 candidate suburbs out from total 698 suburbs from Sydney metro area that meet the requirments (low property price, high population, middle age range and least competitors) for opening up an Italian restaurant. Further looking into the restaurant profile of these 5 suburbs, considering the diversity of restaurant types, both **Randwick** and **Chatswood** are stand out. The diverse restaurant types within a given suburb may imply that the local customers are willing to try new things and hence provide realatively easy-to-survive operating enviornment for a new restaurant in our case. In addition, if we consider location factor between these two suburbs, Randwick has an clear advantage over Chatswood. Coogee beach is within one kilometer from the centre of Randwick. The Univeristy of New South Wales also locates next to Randwick, which provides a large potential customer pool from all around the world. Most importantly, with the newly operated [Sydney light rail](https://sydneylightrail.transport.nsw.gov.au/), potential customers from CBD only need further 15-20min to get to Randwick.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken together, Randwick is the final suburb we should consider to open up a Italian restaurant. We also should note that this is just a very primitive analysis using public datasets. We are only able to solve a few factors that are significant in selecting restaurant location. For example, we have yet to address the demographic composition, the customer flow rate and parking space. These information could enable us to further understand the operation feseabiliy of italian restaurant within Randwick area. Nevertheless, this analysis showcases the magic power of data science in solving real-world problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
